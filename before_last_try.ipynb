{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "3UkPyMhEDt"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "ZXhGmR7SN5"
      },
      "source": [
        "Imports libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FUOZUgggq1"
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "import itertools\n",
        "import random\n",
        "import math\n",
        "import json\n",
        "import logging\n",
        "import pathlib\n",
        "import sys\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tqdm # progree bar\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers.modeling_outputs import Seq2SeqLMOutput"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "EigAhJwddV"
      },
      "source": [
        "DATA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "kXOYfvqlY4"
      },
      "source": [
        "def read_json(path):\n",
        "    with open(path, 'r', encoding='utf-8') as fin:\n",
        "        data = json.load(fin)\n",
        "    return data\n",
        "\n",
        "def write_json(path, data):\n",
        "    with open(path, 'w', encoding='utf-8') as fout:\n",
        "        json.dump(data, fout)\n",
        "\n",
        "\n",
        "class ARDDataset(Dataset):\n",
        "    def __init__(self, path, is_test=False) -> None:\n",
        "        super().__init__()\n",
        "        self.is_test = is_test\n",
        "        self.data = read_json(path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sample = self.data[index]\n",
        "        if self.is_test:\n",
        "            return sample[\"id\"], sample[\"word\"], sample[\"gloss\"],\n",
        "        else:\n",
        "            return sample[\"id\"], sample[\"word\"], sample[\"gloss\"], sample[\"electra\"], sample[\"bertseg\"], sample['bertmsa']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "BOS = \"<seq>\"\n",
        "EOS = \"</seq>\"\n",
        "PAD = \"<pad/>\"\n",
        "UNK = \"<unk/>\"\n",
        "\n",
        "SUPPORTED_ARCHS = ([\"sgns\"])\n",
        "\n",
        "# A dataset is a container object for the actual data\n",
        "class JSONDataset(Dataset):\n",
        "    \"\"\"Reads a CODWOE JSON dataset\"\"\"\n",
        "\n",
        "    def __init__(self, file, vocab=None, freeze_vocab=False, maxlen=256):\n",
        "        \"\"\"\n",
        "        Construct a torch.utils.data.Dataset compatible with torch data API and\n",
        "        codwoe data.\n",
        "        args: `file` the path to the dataset file\n",
        "              `vocab` a dictionary mapping strings to indices\n",
        "              `freeze_vocab` whether to update vocabulary, or just replace unknown items with OOV token\n",
        "              `maxlen` the maximum number of tokens per gloss\n",
        "        \"\"\"\n",
        "        if vocab is None:\n",
        "            self.vocab = defaultdict(count().__next__)\n",
        "        else:\n",
        "            self.vocab = defaultdict(count(len(vocab)).__next__)\n",
        "            self.vocab.update(vocab)\n",
        "        pad, eos, bos, unk = (\n",
        "            self.vocab[PAD],\n",
        "            self.vocab[EOS],\n",
        "            self.vocab[BOS],\n",
        "            self.vocab[UNK],\n",
        "        )\n",
        "        if freeze_vocab:\n",
        "            self.vocab = dict(vocab)\n",
        "        with open(file, \"r\") as istr:\n",
        "            self.items = json.load(istr)\n",
        "        # preparse data\n",
        "        for json_dict in self.items:\n",
        "            # in definition modeling test datasets, gloss targets are absent\n",
        "            if \"gloss\" in json_dict:\n",
        "                json_dict[\"gloss_tensor\"] = torch.tensor(\n",
        "                    [bos]\n",
        "                    + [\n",
        "                        self.vocab[word]\n",
        "                        if not freeze_vocab\n",
        "                        else self.vocab.get(word, unk)\n",
        "                        for word in json_dict[\"gloss\"].split()\n",
        "                    ]\n",
        "                    + [eos]\n",
        "                )\n",
        "                if maxlen:\n",
        "                    json_dict[\"gloss_tensor\"] = json_dict[\"gloss_tensor\"][:maxlen]\n",
        "            # in reverse dictionary test datasets, vector targets are absent\n",
        "            for arch in SUPPORTED_ARCHS:\n",
        "                if arch in json_dict:\n",
        "\n",
        "                    json_dict[f\"{arch}_tensor\"] = torch.tensor(json_dict[arch])\n",
        "            if \"electra\" in json_dict:\n",
        "                json_dict[\"electra_tensor\"] = torch.tensor(json_dict[\"electra\"])\n",
        "            elif \"bertseg\" in json_dict:\n",
        "                json_dict[\"bertseg_tensor\"] = torch.tensor(json_dict[\"bertseg\"])\n",
        "            elif \"bertmsa\" in json_dict:\n",
        "                json_dict[\"bertmsa_tensor\"] = torch.tensor(json_dict[\"bertmsa\"])\n",
        "        self.has_gloss = \"gloss\" in self.items[0]\n",
        "        self.has_vecs = SUPPORTED_ARCHS[0] in self.items[0]\n",
        "        self.has_electra = \"electra\" in self.items[0]\n",
        "        self.has_bertseg = \"bertseg\" in self.items[0]\n",
        "        self.has_bertmsa = \"bertmsa\" in self.items[0]\n",
        "        self.itos = sorted(self.vocab, key=lambda w: self.vocab[w])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.items[index]\n",
        "\n",
        "    # we're adding this method to simplify the code in our predictions of\n",
        "    # glosses\n",
        "    def decode(self, tensor):\n",
        "        \"\"\"Convert a sequence of indices (possibly batched) to tokens\"\"\"\n",
        "        with torch.no_grad():\n",
        "            if tensor.dim() == 2:\n",
        "                # we have batched tensors of shape [Seq x Batch]\n",
        "                decoded = []\n",
        "                for tensor_ in tensor.t():\n",
        "                    decoded.append(self.decode(tensor_))\n",
        "                return decoded\n",
        "            else:\n",
        "                return \" \".join(\n",
        "                    [self.itos[i.item()] for i in tensor if i != self.vocab[PAD]]\n",
        "                )\n",
        "\n",
        "    def save(self, file):\n",
        "        torch.save(self, file)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file):\n",
        "        return torch.load(file)\n",
        "\n",
        "\n",
        "# A sampler allows you to define how to select items from your Dataset. Torch\n",
        "# provides a number of default Sampler classes\n",
        "class TokenSampler(Sampler):\n",
        "    \"\"\"Produce batches with up to `batch_size` tokens in each batch\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, dataset, batch_size=200, size_fn=len, drop_last=False, shuffle=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        args: `dataset` a torch.utils.data.Dataset (iterable style)\n",
        "              `batch_size` the maximum number of tokens in a batch\n",
        "              `size_fn` a callable that yields the number of tokens in a dataset item\n",
        "              `drop_last` if True and the data can't be divided in exactly the right number of batch, drop the last batch\n",
        "              `shuffle` if True, shuffle between every iteration\n",
        "        \"\"\"\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.size_fn = size_fn\n",
        "        self._len = None\n",
        "        self.drop_last = drop_last\n",
        "        self.shuffle = True\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = range(len(self.dataset))\n",
        "        if self.shuffle:\n",
        "            indices = list(indices)\n",
        "            random.shuffle(indices)\n",
        "        i = 0\n",
        "        selected = []\n",
        "        numel = 0\n",
        "        longest_len = 0\n",
        "        for i in indices:\n",
        "            if numel + self.size_fn(self.dataset[i]) > self.batch_size:\n",
        "                if selected:\n",
        "                    yield selected\n",
        "                selected = []\n",
        "                numel = 0\n",
        "            numel += self.size_fn(self.dataset[i])\n",
        "            selected.append(i)\n",
        "        if selected and not self.drop_last:\n",
        "            yield selected\n",
        "\n",
        "    def __len__(self):\n",
        "        if self._len is None:\n",
        "            self._len = (\n",
        "                sum(self.size_fn(self.dataset[i]) for i in range(len(self.dataset)))\n",
        "                // self.batch_size\n",
        "            )\n",
        "        return self._len\n",
        "\n",
        "\n",
        "# DataLoaders give access to an iterator over the dataset, using a sampling\n",
        "# strategy as defined through a Sampler.\n",
        "def get_dataloader(dataset, batch_size=200, shuffle=True):\n",
        "    \"\"\"produce dataloader.\n",
        "    args: `dataset` a torch.utils.data.Dataset (iterable style)\n",
        "          `batch_size` the maximum number of tokens in a batch\n",
        "          `shuffle` if True, shuffle between every iteration\n",
        "    \"\"\"\n",
        "    # some constants for the closures\n",
        "    has_gloss = dataset.has_gloss\n",
        "    has_vecs = dataset.has_vecs\n",
        "    has_electra = dataset.has_electra\n",
        "    has_bertseg = dataset.has_bertseg\n",
        "    has_bertmsa = dataset.has_bertmsa\n",
        "    PAD_idx = dataset.vocab[PAD]\n",
        "\n",
        "    # the collate function has to convert a list of dataset items into a batch\n",
        "    def do_collate(json_dicts):\n",
        "        \"\"\"collates example into a dict batch; produces ands pads tensors\"\"\"\n",
        "        batch = defaultdict(list)\n",
        "        for jdict in json_dicts:\n",
        "            for key in jdict:\n",
        "                batch[key].append(jdict[key])\n",
        "        if has_gloss:\n",
        "            batch[\"gloss_tensor\"] = pad_sequence(\n",
        "                batch[\"gloss_tensor\"], padding_value=PAD_idx, batch_first=False\n",
        "            )\n",
        "        if has_vecs:\n",
        "            for arch in SUPPORTED_ARCHS:\n",
        "                batch[f\"{arch}_tensor\"] = torch.stack(batch[f\"{arch}_tensor\"])\n",
        "        if has_electra:\n",
        "            batch[\"electra_tensor\"] = torch.stack(batch[\"electra_tensor\"])\n",
        "        if has_bertseg:\n",
        "            batch[\"bertseg_tensor\"] = torch.stack(batch[\"bertseg_tensor\"])\n",
        "        if has_bertmsa:\n",
        "            batch[\"bertmsa_tensor\"] = torch.stack(batch[\"bertmsa_tensor\"])\n",
        "        return dict(batch)\n",
        "\n",
        "    if dataset.has_gloss:\n",
        "        # we try to keep the amount of gloss tokens roughly constant across all\n",
        "        # batches.\n",
        "        def do_size_item(item):\n",
        "            \"\"\"retrieve tensor size, so as to batch items per elements\"\"\"\n",
        "            return item[\"gloss_tensor\"].numel()\n",
        "\n",
        "        return DataLoader(\n",
        "            dataset,\n",
        "            collate_fn=do_collate,\n",
        "            batch_sampler=TokenSampler(\n",
        "                dataset, batch_size=batch_size, size_fn=do_size_item, shuffle=shuffle\n",
        "            ),\n",
        "        )\n",
        "    else:\n",
        "        # there's no gloss, hence no gloss tokens, so we use a default batching\n",
        "        # strategy.\n",
        "        return DataLoader(\n",
        "            dataset, collate_fn=do_collate, batch_size=batch_size, shuffle=shuffle\n",
        "        )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "FMDCMraGGq"
      },
      "source": [
        "Models "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "MGMfigny5S"
      },
      "source": [
        "class AraT5RevDict(nn.Module):\n",
        "    def __init__(self, max_len) -> None:\n",
        "        super().__init__()\n",
        "        model_config = AutoConfig.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n",
        "        self.base_model = AutoModelForSeq2SeqLM.from_config(model_config)\n",
        "        self.linear = nn.Linear(self.base_model.config.hidden_size, max_len)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        outputs:Seq2SeqLMOutput = self.base_model(input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels,\n",
        "            return_dict=True\n",
        "        )\n",
        "\n",
        "        pooled_emb = (outputs.encoder_last_hidden_state * attention_mask.unsqueeze(2)).sum(dim=1) / attention_mask.sum(dim=1).unsqueeze(1)\n",
        "\n",
        "        embedding = self.linear(pooled_emb)\n",
        "        return outputs.loss, embedding\n",
        "\n",
        "    def save(self, file):\n",
        "        torch.save(self, file)\n",
        "        print(\"\\n--\\nsave1\\n--\\n\")\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file):\n",
        "        return torch.load(file)\n",
        "\n",
        "class ARBERTRevDict(nn.Module):\n",
        "    def __init__(self, args) -> None:\n",
        "        super().__init__()\n",
        "        if args.resume_train:\n",
        "            self.base_model = AutoModel.from_pretrained(args.resume_file)\n",
        "            raise NotImplementedError()\n",
        "        else:\n",
        "            if args.from_pretrained:\n",
        "                self.base_model = AutoModel.from_pretrained(args.model_name)\n",
        "            else:\n",
        "                model_config = AutoConfig.from_pretrained(args.model_name)\n",
        "                self.base_model = AutoModel.from_config(model_config)\n",
        "\n",
        "        self.linear = nn.Linear(self.base_model.config.hidden_size, args.max_len)\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids , attention_mask):\n",
        "        feats = self.base_model(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "        embedding = self.linear(feats)\n",
        "        return embedding\n",
        "\n",
        "    def save(self, file):\n",
        "        self.base_model.save_pretrained(file,from_pt=True)\n",
        "        print(\"\\n--\\nsave_pretrained\\n--\\n\")\n",
        "        # torch.save(self, file)\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file):\n",
        "        return AutoModel.from_pretrained(file)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"From PyTorch\"\"\"\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=4096):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0)]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "\n",
        "class RevdictModel(nn.Module):\n",
        "    \"\"\"A transformer architecture for Reverse Dictionary\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, vocab, d_model=256, n_head=4, n_layers=4, dropout=0.3, maxlen=512\n",
        "    ):\n",
        "        super(RevdictModel, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.padding_idx = vocab[PAD]\n",
        "        self.eos_idx = vocab[EOS]\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "        self.embedding = nn.Embedding(len(vocab), d_model, padding_idx=self.padding_idx)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            d_model, dropout=dropout, max_len=maxlen\n",
        "        )\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=n_head, dropout=dropout, dim_feedforward=d_model * 2\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=n_layers\n",
        "        )\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.e_proj = nn.Linear(d_model, d_model)\n",
        "        for name, param in self.named_parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "            elif \"bias\" in name:\n",
        "                nn.init.zeros_(param)\n",
        "            else:  # gain parameters of the layer norm\n",
        "                nn.init.ones_(param)\n",
        "\n",
        "    def forward(self, gloss_tensor):\n",
        "        src_key_padding_mask = gloss_tensor == self.padding_idx\n",
        "        embs = self.embedding(gloss_tensor)\n",
        "        src = self.positional_encoding(embs)\n",
        "        transformer_output = self.dropout(\n",
        "            self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask.t())\n",
        "        )\n",
        "        summed_embs = transformer_output.masked_fill(\n",
        "            src_key_padding_mask.unsqueeze(-1), 0\n",
        "        ).sum(dim=0)\n",
        "        return self.e_proj(F.relu(summed_embs))\n",
        "\n",
        "    @staticmethod\n",
        "    def load(file):\n",
        "        return torch.load(file)\n",
        "\n",
        "    def save(self, file):\n",
        "        torch.save(self, file)\n",
        "        print(\"\\n--\\nsave2\\n--\\n\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "MG9aNHIFnS"
      },
      "source": [
        "Model uses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "NmFhjsgvIz"
      },
      "source": [
        "def train(args):\n",
        "    # assert args.train_file is not None, \"Missing dataset for training\"\n",
        "    # 1. get data, vocabulary, summary writer\n",
        "    # logger.debug(\"Preloading data\")\n",
        "    ## make datasets\n",
        "    # train_dataset = ARDDataset(args.train_file)\n",
        "    # valid_dataset = ARDDataset(args.dev_file)\n",
        "\n",
        "    ## make dataloader\n",
        "    # train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=args.batch_size)\n",
        "    # valid_dataloader = DataLoader(valid_dataset, batch_size=args.batch_size)\n",
        "    ## make summary writer\n",
        "    # summary_writer = SummaryWriter(args.save_dir / args.summary_logdir)\n",
        "    # train_step = itertools.count()  # to keep track of the training steps for logging\n",
        "\n",
        "    # 2. construct model\n",
        "    ## Hyperparams\n",
        "    # logger.debug(\"Setting up training environment\")\n",
        "\n",
        "    model = AraT5RevDict(args).to(args.device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
        "    model.train()\n",
        "\n",
        "    # 3. declare optimizer & loss_fn\n",
        "    ## Hyperparams\n",
        "    EPOCHS, LEARNING_RATE, BETA1, BETA2, WEIGHT_DECAY = args.num_epochs, 1.0e-4, 0.9, 0.999, 1.0e-6\n",
        "    optimizer = optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=LEARNING_RATE,\n",
        "        betas=(BETA1, BETA2),\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    vec_tensor_key = f\"{args.target_arch}_tensor\"\n",
        "\n",
        "    best_cosine = 0\n",
        "\n",
        "    # 4. train model\n",
        "    for epoch in tqdm.trange(EPOCHS, desc=\"Epochs\"):\n",
        "        ## train loop\n",
        "        pbar = tqdm.tqdm(\n",
        "            desc=f\"Train {epoch}\", total=len(train_dataset), disable=None, leave=False\n",
        "        )\n",
        "        for ids, word, gloss, electra, bertseg, bertmsa in train_dataloader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(args.device)\n",
        "            gloss_tokens = tokenizer(gloss, padding=True, return_tensors='pt').to(args.device)\n",
        "\n",
        "            if args.target_arch == \"electra\":\n",
        "                target_embs = torch.stack(electra, dim=1).to(args.device)\n",
        "            elif args.target_arch ==\"bertseg\":\n",
        "                target_embs = torch.stack(bertseg, dim=1).to(args.device)\n",
        "            elif args.target_arch ==\"bertmsa\":\n",
        "                target_embs = torch.stack(bertmsa, dim=1).to(args.device)\n",
        "\n",
        "            target_embs = target_embs.float()\n",
        "\n",
        "            ce_loss, pred_embs = model(\n",
        "                gloss_tokens[\"input_ids\"],\n",
        "                gloss_tokens[\"attention_mask\"],\n",
        "                word_tokens[\"input_ids\"],\n",
        "            )\n",
        "\n",
        "            mse_loss = loss_fn(pred_embs, target_embs)\n",
        "            loss = args.ce_loss_weight * ce_loss + mse_loss\n",
        "            loss.backward()\n",
        "\n",
        "            # keep track of the train loss for this step\n",
        "            next_step = next(train_step)\n",
        "            summary_writer.add_scalar(\n",
        "                \"revdict-train/cos\",\n",
        "                F.cosine_similarity(pred_embs, target_embs).mean().item(),\n",
        "                next_step,\n",
        "            )\n",
        "            summary_writer.add_scalar(\"revdict-train/mse\", loss.item(), next_step)\n",
        "            optimizer.step()\n",
        "            pbar.update(target_embs.size(0))\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "\n",
        "        ## eval loop\n",
        "        if args.dev_file:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                sum_dev_loss, sum_cosine, sum_rnk = 0.0, 0.0, 0.0\n",
        "                pbar = tqdm.tqdm(\n",
        "                    desc=f\"Eval {epoch}\",\n",
        "                    total=len(valid_dataset),\n",
        "                    disable=None,\n",
        "                    leave=False,\n",
        "                )\n",
        "                pred_embs_list, target_embs_list = [], []\n",
        "                for ids, word, gloss, electra, bertseg, bertmsa in valid_dataloader:\n",
        "                    # word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(args.device)\n",
        "                    # gloss_tokens = tokenizer(gloss, max_length=512, padding=True, truncation=True, return_tensors='pt').to(args.device)\n",
        "\n",
        "                    word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(args.device)\n",
        "                    gloss_tokens = tokenizer(gloss, padding=True, return_tensors='pt').to(args.device)\n",
        "\n",
        "                    if args.target_arch == \"electra\":\n",
        "                        target_embs = torch.stack(electra, dim=1).to(args.device)\n",
        "                    elif args.target_arch == \"bertseg\":\n",
        "                        target_embs = torch.stack(bertseg, dim=1).to(args.device)\n",
        "                    elif args.target_arch == \"bertmsa\":\n",
        "                        target_embs = torch.stack(bertmsa, dim=1).to(args.device)\n",
        "\n",
        "                    target_embs = target_embs.float()\n",
        "\n",
        "                    ce_loss, pred_embs = model(\n",
        "                        gloss_tokens[\"input_ids\"],\n",
        "                        gloss_tokens[\"attention_mask\"],\n",
        "                        word_tokens[\"input_ids\"],\n",
        "                    )\n",
        "\n",
        "                    mse_loss = loss_fn(pred_embs, target_embs)\n",
        "                    loss = args.ce_loss_weight * ce_loss + mse_loss\n",
        "\n",
        "                    # sum_dev_loss += (\n",
        "                    #     F.mse_loss(pred_embs, target_embs, reduction=\"none\").mean(1).sum().item()\n",
        "                    # )\n",
        "                    sum_dev_loss += loss.item()\n",
        "                    sum_cosine += F.cosine_similarity(pred_embs, target_embs).sum().item()\n",
        "\n",
        "                    # sum_rnk += rank_cosine(pred_embs, target_embs)\n",
        "\n",
        "                    pred_embs_list.append(pred_embs.cpu())\n",
        "                    target_embs_list.append(target_embs.cpu())\n",
        "\n",
        "                    pbar.update(target_embs.size(0))\n",
        "\n",
        "                sum_rnk = rank_cosine(torch.cat(pred_embs_list, dim=0), torch.cat(target_embs_list, dim=0))\n",
        "\n",
        "                pbar = tqdm.tqdm(\n",
        "                    desc=f\"Eval {epoch} cos: \"+str(sum_cosine / len(valid_dataset))+\" mse: \"+str( sum_dev_loss / len(valid_dataset) )+\" rnk: \"+str(sum_rnk/ len(valid_dataset))+ \" sum_rnk: \"+str(sum_rnk)+\" len of dev: \"+str(len(valid_dataset)) +\"\\n\",\n",
        "                    total=len(valid_dataset),\n",
        "                    disable=None,\n",
        "                    leave=False,\n",
        "                )\n",
        "\n",
        "                if sum_cosine >= best_cosine:\n",
        "                    best_cosine = sum_cosine\n",
        "                    print(f\"Saving Best Checkpoint at Epoch {epoch} best cosine {best_cosine} .\")\n",
        "                    model.save(args.save_dir / args.best_model)\n",
        "\n",
        "\n",
        "                # keep track of the average loss on dev set for this epoch\n",
        "                summary_writer.add_scalar(\n",
        "                    \"revdict-dev/cos\", sum_cosine / len(valid_dataset), epoch\n",
        "                )\n",
        "                summary_writer.add_scalar(\n",
        "                    \"revdict-dev/mse\", sum_dev_loss / len(valid_dataset), epoch\n",
        "                )\n",
        "                summary_writer.add_scalar(\n",
        "                    \"revdict-dev/rnk\", sum_rnk / len(valid_dataset), epoch\n",
        "                )\n",
        "                pbar.close()\n",
        "                model.train()\n",
        "\n",
        "        model.save(args.save_dir / \"model_epoch.pt\")\n",
        "\n",
        "    # 5. save result\n",
        "    model.save(args.save_dir / args.last_state_model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "5peEla71Wi"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "from collections import defaultdict\n",
        "from itertools import count\n",
        "\n",
        "import string\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pyarabic.araby as arab\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset, Sampler\n",
        "\n",
        "from transformers import BertTokenizer, BertModel, AutoModel, AutoConfig, AutoModelForSeq2SeqLM\n",
        "from transformers.modeling_outputs import Seq2SeqLMOutput\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "2XMKEpVp7M"
      },
      "source": [
        "# preprocess_text functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "T0xkXqtX8a"
      },
      "source": [
        "stop_words = list(set(stopwords.words('arabic')))\n",
        "a_dict = r\"\"\"\n",
        "                             \u0651    | # Tashdid\n",
        "                             \u064e    | # Fatha\n",
        "                             \u064b    | # Tanwin Fath\n",
        "                             \u064f    | # Damma\n",
        "                             \u064c    | # Tanwin Damm\n",
        "                             \u0650    | # Kasra\n",
        "                             \u064d    | # Tanwin Kasr\n",
        "                             \u0652    | # Sukun\n",
        "                            \u0640    | # Tatwil/Kashida\n",
        "                     \"\"\"\n",
        "regex_pattern = (\n",
        "    \"\\U0001F600-\\U0001F64F\"+  # emoticons {\ud83d\ude00 , \ud83d\ude06} \n",
        "    \"\\U0001F300-\\U0001F5FF\"+  # symbols & pictographs {\ud83c\udf0d , \ud83c\udf1e}\n",
        "    \"\\U0001F680-\\U0001F6FF\"+  # transport & map symbols {\ud83d\ude8c , \ud83d\ude95 }\n",
        "    \"\\U0001F1E0-\\U0001F1FF\"   # flags (iOS) { \ud83c\uddfa\ud83c\uddf8 , \ud83c\udde8\ud83c\udde6 }\n",
        ") \n",
        "def preprocess_text(text):\n",
        "    # Remove special characters {& $ @} and punctuation {. , ? !}\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Remove Arabic diacritics\n",
        "    text = re.sub(a_dict, '', text)\n",
        "\n",
        "    # Remove emoji characters \n",
        "    text = re.sub(f\"[{regex_pattern}]\", '', text)    \n",
        "    \n",
        "    # Tokeniz The Sentence into tokens\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    \n",
        "    return preprocessed_text"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "nCnd0vd9VI"
      },
      "source": [
        "model = AraT5RevDict(256).to(\"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "z5PcpCIk9W"
      },
      "source": [
        "dataset = ARDDataset(\"dev.json\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "GfZkQQscN2"
      },
      "source": [
        "data = dataset[0]\n",
        "# data"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "qVL4x6RN8V"
      },
      "source": [
        "_id = data[0]\n",
        "word = data[1]\n",
        "gloss = data[2]\n",
        "electra = data[3]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FR2IwijdHY"
      },
      "source": [
        "word\n",
        "gloss\n",
        "electra"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "[0.2265725881,\n -0.3225077391,\n 0.5538389087,\n 0.5800347328,\n -0.0342517458,\n -0.0777392015,\n 0.2868331671,\n 0.689817667,\n 0.5971964598,\n 0.4828594625,\n 0.0246522464,\n 0.2119424343,\n 0.0674103796,\n 0.3009205461,\n -0.8413527608,\n -0.0168413986,\n 0.2170748115,\n 0.5729941726,\n -0.1633950323,\n -0.3820695877,\n 0.5487265587,\n -0.7529748678,\n 0.681463778,\n 0.6414878368,\n 0.4434165657,\n -0.6303778291,\n 0.4416134059,\n 0.0699960962,\n 1.3176093102,\n -0.3285644054,\n 0.2450650483,\n -0.0553470254,\n 0.49709481,\n -0.4185130298,\n 0.5858063698,\n -0.0439687595,\n 1.3485478163,\n -0.9497126937,\n 0.1511357725,\n 0.2152087986,\n -0.4863995016,\n 0.3027804792,\n -0.0959090516,\n -0.0409083292,\n -0.8452766538,\n -0.1000854522,\n -0.4719405472,\n -0.0783871412,\n 0.788713932,\n -0.1880373061,\n 0.2888511419,\n 1.185285449,\n 0.5520726442,\n -0.8278334141,\n 0.6819879413,\n -0.2602242529,\n 0.1381222904,\n 0.1392377019,\n 0.0435579084,\n -0.4877517521,\n -0.0483157523,\n -0.2761443555,\n 0.4849563539,\n -0.4398656189,\n -0.0801035389,\n 0.0903152972,\n 0.0117620602,\n 0.3185898066,\n -0.6859471202,\n -0.5259308219,\n 0.0464327931,\n -0.3840228617,\n 1.0246995687,\n 0.8888031244,\n -0.750652194,\n -1.1357411146,\n -0.3237901926,\n -0.0269558169,\n -0.7846989632,\n -1.0208777189,\n 0.5858547091,\n -0.8039185405,\n 0.2842886448,\n -0.5100001693,\n 0.775423944,\n 1.1103876829,\n -0.6913213134,\n 0.5530064702,\n 0.1032351851,\n 0.560996294,\n 1.0204173326,\n -0.7724400759,\n 0.4080898166,\n -0.7806475163,\n -0.6322034597,\n -0.2793534994,\n 0.8084936142,\n 0.2857028544,\n 0.5466604233,\n 1.0331897736,\n -0.2343531102,\n 0.1204010695,\n -0.1634868979,\n -2.3362674713,\n -0.3474829793,\n -0.3708215058,\n 0.9748392701,\n -0.205939278,\n -1.0027031898,\n 0.3349891901,\n 0.2745612264,\n 0.0182442646,\n -0.2833275795,\n -0.1056369394,\n -0.5322461128,\n 0.1868901551,\n 0.2806655467,\n -0.2771494687,\n -0.7598552704,\n -0.8811417222,\n 0.066262655,\n 0.1606631577,\n -1.3338551521,\n 0.8369606733,\n 1.0128974915,\n 0.3725076616,\n 0.8179664016,\n 0.2023696005,\n -0.1542117596,\n 0.8691690564,\n 0.4566861093,\n 0.273257792,\n -0.1298032701,\n -0.186212182,\n 0.8600626588,\n -0.23441872,\n -0.2531741858,\n 0.6876239777,\n -0.6028783321,\n -0.2644580901,\n -0.1416347474,\n -0.306841433,\n -0.1631717384,\n -0.9027474523,\n 0.2275801152,\n 0.6702797413,\n -0.5411435366,\n -0.3338004053,\n -0.1534097493,\n -0.4538152814,\n 0.1572257131,\n -0.1385594159,\n -0.6095362902,\n 0.6909813285,\n -0.6891449094,\n 0.1263076812,\n 0.2535048425,\n 1.0377175808,\n 0.9073767066,\n -0.0242622737,\n -0.0280419923,\n 0.4975720048,\n -0.4190764725,\n -0.3054497242,\n 0.5487508774,\n 0.3729883432,\n 0.9873837829,\n -0.7479969859,\n 0.1643162966,\n 0.2255522907,\n 0.0156333316,\n -0.3285777867,\n -0.071144864,\n -0.2573470771,\n 0.1578045338,\n 0.5112911463,\n -0.5244684219,\n -0.5655391216,\n 0.1709309518,\n -0.4642157257,\n -0.5997709632,\n 0.0197334625,\n -0.4807826877,\n 0.336075455,\n 0.1685454249,\n 0.2587662041,\n -0.3158641756,\n 0.1964189708,\n 0.1309700906,\n -0.7870230675,\n 0.3890202045,\n 0.5550039411,\n -0.673009336,\n 0.0626640096,\n 0.1232943088,\n -0.1912157834,\n -0.2634037137,\n -0.2737855315,\n -0.9004274607,\n 0.2958536148,\n -0.9475852847,\n 0.6348979473,\n 0.8078267574,\n 0.7713714838,\n 0.3662464917,\n -0.0577990487,\n 0.0410278141,\n 0.0328952484,\n 0.0341378003,\n -1.0538666248,\n 0.846595645,\n -0.6743401885,\n 0.1174692363,\n 0.444468081,\n 0.5119974613,\n 0.5246697664,\n 0.4406267405,\n 0.8784813285,\n 0.9330447912,\n 0.3846928179,\n 0.1293181926,\n -0.2222085893,\n 0.0483406037,\n -0.4021352232,\n 0.7328829765,\n -0.6286907792,\n 0.0138378385,\n 0.1880706996,\n 0.6824198365,\n -0.1741601527,\n -0.8042005897,\n 0.3986111581,\n 0.1075260043,\n -0.6292765141,\n 1.7214009762,\n -0.2249072343,\n 0.027728837,\n -0.0825389624,\n 1.1485315561,\n -0.0703995153,\n 0.5271876454,\n -0.2647045851,\n 0.834530592,\n -0.5739616156,\n 0.9234867692,\n 0.6498302817,\n 0.3352903426,\n -0.9881728292,\n 0.3054727614,\n -1.6641254425,\n 0.7585619688,\n 0.4025826156,\n -0.1055731997,\n -0.6223256588,\n 0.2661118805,\n -0.5677054524]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gQ0wH8oUKX"
      },
      "source": [
        "# word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(\"cpu\")\n",
        "# gloss_tokens = tokenizer(gloss, padding=True, return_tensors='pt').to(\"cpu\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "vVZ05JzrlP"
      },
      "source": [
        "word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(\"cpu\")\n",
        "gloss_tokens = tokenizer(preprocess_text(gloss), padding=True, return_tensors='pt').to(\"cpu\")\n",
        "\n",
        "print(word_tokens)\n",
        "print(gloss_tokens)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'input_ids': tensor([[46269,  4412, 30597,     1]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n{'input_ids': tensor([[20381,   219, 29232,  2437,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "mJqeZ7lhno"
      },
      "source": [],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "{'input_ids': tensor([[46269,  4412, 30597,     1]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "190wsRJZle"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "d11qFzRnDQ"
      },
      "source": [
        "# target_embs = torch.stack(electra, dim=1).to(\"cpu\")\n",
        "# target_embs = target_embs.float()\n",
        "ce_loss, pred_embs = model(\n",
        "    gloss_tokens[\"input_ids\"],\n",
        "    gloss_tokens[\"attention_mask\"],\n",
        "    word_tokens[\"input_ids\"],\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bD11mmOeFK"
      },
      "source": [
        "pred_embs\n",
        "# ce_loss"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "tensor(135.2611, grad_fn=<NllLossBackward0>)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "3fanQCYPsL"
      },
      "source": [
        "model = AraT5RevDict(256).to(\"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"UBC-NLP/AraT5v2-base-1024\")\n",
        "\n",
        "model.train()\n",
        "# 3. declare optimizer & loss_fn\n",
        "## Hyperparams\n",
        "EPOCHS, LEARNING_RATE, BETA1, BETA2, WEIGHT_DECAY = 5, 1.0e-4, 0.9, 0.999, 1.0e-6\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LEARNING_RATE,\n",
        "    betas=(BETA1, BETA2),\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "\n",
        "vec_tensor_key = f\"{args.target_arch}_tensor\"\n",
        "\n",
        "best_cosine = 0\n",
        "\n",
        "# 4. train model\n",
        "for epoch in tqdm.trange(EPOCHS, desc=\"Epochs\"):\n",
        "    ## train loop\n",
        "    pbar = tqdm.tqdm(\n",
        "        desc=f\"Train {epoch}\", total=len(train_dataset), disable=None, leave=False\n",
        "    )\n",
        "    for ids, word, gloss, electra, bertseg, bertmsa in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(\"cpu\")\n",
        "        gloss_tokens = tokenizer(gloss, padding=True, return_tensors='pt').to(\"cpu\")\n",
        "\n",
        "        # if args.target_arch == \"electra\":\n",
        "        #     target_embs = torch.stack(electra, dim=1).to(args.device)\n",
        "        # elif args.target_arch ==\"bertseg\":\n",
        "        #     target_embs = torch.stack(bertseg, dim=1).to(args.device)\n",
        "        # elif args.target_arch ==\"bertmsa\":\n",
        "        #     target_embs = torch.stack(bertmsa, dim=1).to(args.device)\n",
        "\n",
        "        target_embs = torch.stack(electra, dim=1).to(\"cpu\")\n",
        "        target_embs = target_embs.float()\n",
        "        ce_loss, pred_embs = model(\n",
        "            gloss_tokens[\"input_ids\"],\n",
        "            gloss_tokens[\"attention_mask\"],\n",
        "            word_tokens[\"input_ids\"],\n",
        "        )\n",
        "\n",
        "        mse_loss = loss_fn(pred_embs, target_embs)\n",
        "        loss = 1 * ce_loss + mse_loss\n",
        "        loss.backward()\n",
        "\n",
        "        # keep track of the train loss for this step\n",
        "        # next_step = next(train_step)\n",
        "        # summary_writer.add_scalar(\n",
        "        #     \"revdict-train/cos\",\n",
        "        #     F.cosine_similarity(pred_embs, target_embs).mean().item(),\n",
        "        #     next_step,\n",
        "        # )\n",
        "        # summary_writer.add_scalar(\"revdict-train/mse\", loss.item(), next_step)\n",
        "        # optimizer.step()\n",
        "        # pbar.update(target_embs.size(0))\n",
        "\n",
        "    # pbar.close()\n",
        "\n",
        "\n",
        "    ## eval loop\n",
        "    # if args.dev_file:\n",
        "        # model.save(args.save_dir / \"model_epoch.pt\")\n",
        "\n",
        "# 5. save result\n",
        "# model.save(args.save_dir / args.last_state_model)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "FbHhBdsOhz"
      },
      "source": [
        "eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "vumFYLC7mw"
      },
      "source": [
        "# model.eval()\n",
        "# with torch.no_grad():\n",
        "#     sum_dev_loss, sum_cosine, sum_rnk = 0.0, 0.0, 0.0\n",
        "#     pbar = tqdm.tqdm(\n",
        "#         desc=f\"Eval {epoch}\",\n",
        "#         total=len(valid_dataset),\n",
        "#         disable=None,\n",
        "#         leave=False,\n",
        "#     )\n",
        "#     pred_embs_list, target_embs_list = [], []\n",
        "#     for ids, word, gloss, electra, bertseg, bertmsa in valid_dataloader:\n",
        "#         # word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(args.device)\n",
        "#         # gloss_tokens = tokenizer(gloss, max_length=512, padding=True, truncation=True, return_tensors='pt').to(args.device)\n",
        "\n",
        "#         word_tokens = tokenizer(word, padding=True, return_tensors='pt').to(args.device)\n",
        "#         gloss_tokens = tokenizer(gloss, padding=True, return_tensors='pt').to(args.device)\n",
        "\n",
        "#         if args.target_arch == \"electra\":\n",
        "#             target_embs = torch.stack(electra, dim=1).to(args.device)\n",
        "#         elif args.target_arch == \"bertseg\":\n",
        "#             target_embs = torch.stack(bertseg, dim=1).to(args.device)\n",
        "#         elif args.target_arch == \"bertmsa\":\n",
        "#             target_embs = torch.stack(bertmsa, dim=1).to(args.device)\n",
        "\n",
        "#         target_embs = target_embs.float()\n",
        "\n",
        "#         ce_loss, pred_embs = model(\n",
        "#             gloss_tokens[\"input_ids\"],\n",
        "#             gloss_tokens[\"attention_mask\"],\n",
        "#             word_tokens[\"input_ids\"],\n",
        "#         )\n",
        "\n",
        "#         mse_loss = loss_fn(pred_embs, target_embs)\n",
        "#         loss = args.ce_loss_weight * ce_loss + mse_loss\n",
        "\n",
        "#         # sum_dev_loss += (\n",
        "#         #     F.mse_loss(pred_embs, target_embs, reduction=\"none\").mean(1).sum().item()\n",
        "#         # )\n",
        "#         sum_dev_loss += loss.item()\n",
        "#         sum_cosine += F.cosine_similarity(pred_embs, target_embs).sum().item()\n",
        "\n",
        "#         # sum_rnk += rank_cosine(pred_embs, target_embs)\n",
        "\n",
        "#         pred_embs_list.append(pred_embs.cpu())\n",
        "#         target_embs_list.append(target_embs.cpu())\n",
        "\n",
        "#         pbar.update(target_embs.size(0))\n",
        "\n",
        "#     sum_rnk = rank_cosine(torch.cat(pred_embs_list, dim=0), torch.cat(target_embs_list, dim=0))\n",
        "\n",
        "#     pbar = tqdm.tqdm(\n",
        "#         desc=f\"Eval {epoch} cos: \"+str(sum_cosine / len(valid_dataset))+\" mse: \"+str( sum_dev_loss / len(valid_dataset) )+\" rnk: \"+str(sum_rnk/ len(valid_dataset))+ \" sum_rnk: \"+str(sum_rnk)+\" len of dev: \"+str(len(valid_dataset)) +\"\\n\",\n",
        "#         total=len(valid_dataset),\n",
        "#         disable=None,\n",
        "#         leave=False,\n",
        "#     )\n",
        "\n",
        "#     if sum_cosine >= best_cosine:\n",
        "#         best_cosine = sum_cosine\n",
        "#         print(f\"Saving Best Checkpoint at Epoch {epoch} best cosine {best_cosine} .\")\n",
        "#         model.save(args.save_dir / args.best_model)\n",
        "\n",
        "\n",
        "#     # keep track of the average loss on dev set for this epoch\n",
        "#     summary_writer.add_scalar(\n",
        "#         \"revdict-dev/cos\", sum_cosine / len(valid_dataset), epoch\n",
        "#     )\n",
        "#     summary_writer.add_scalar(\n",
        "#         \"revdict-dev/mse\", sum_dev_loss / len(valid_dataset), epoch\n",
        "#     )\n",
        "#     summary_writer.add_scalar(\n",
        "#         \"revdict-dev/rnk\", sum_rnk / len(valid_dataset), epoch\n",
        "#     )\n",
        "#     pbar.close()\n",
        "#     model.train()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "9BZ2cY8YlX"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}